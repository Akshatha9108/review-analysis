{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ea119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import parse_qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b77d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY=\"headphones\"\n",
    "TOP_N_PRODUCTS=20\n",
    "BASE_URL = 'https://www.flipkart.com/'\n",
    "REVIEW_PAGES_TO_SCRAPE_FROM_PER_PRODUCT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_popular_product_s_titles_and_urls(search_query : str, popular_products_count_limit : int = None):\n",
    "    \n",
    "    search_url = f\"{BASE_URL}search?q={search_query}&sort=popularity\"\n",
    "    search_response = requests.get(search_url)\n",
    "    \n",
    "    search_html_soup = BeautifulSoup(search_response.content, 'html.parser')\n",
    "    search_results_products = search_html_soup.find_all('div',attrs={'class':'_4ddWXP'})\n",
    "    \n",
    "    product_titles, product_urls = [],[]\n",
    "    \n",
    "    product_count = 0\n",
    "    \n",
    "    for product in tqdm(search_results_products, desc=\"Search Results Iteration\", position=0, leave=True):\n",
    "        \n",
    "        ad_mention_subrow = product.find(\"div\", attrs={\"class\":\"_4HTuuX\"})\n",
    "        \n",
    "        is_ad = not not ad_mention_subrow\n",
    "        \n",
    "        if not is_ad:\n",
    "            \n",
    "            title_mention_subrow = product.find(\"a\", attrs={\"class\":\"s1Q9rs\"})\n",
    "            \n",
    "            product_title = title_mention_subrow[\"title\"]\n",
    "            product_relative_url = title_mention_subrow[\"href\"]\n",
    "            product_url = urljoin(BASE_URL,product_relative_url)\n",
    "            \n",
    "            parsed_url = urlparse.urlparse(product_url)\n",
    "            parsed_url_path = parsed_url.path\n",
    "            parsed_url_path_split = parsed_url_path.split(\"/\")\n",
    "            parsed_url_path_split[2] = \"product-reviews\"\n",
    "            parsed_url_path_modified = \"/\".join(parsed_url_path_split)\n",
    "            parsed_url_modified = parsed_url._replace(path=parsed_url_path_modified)\n",
    "            product_url = parsed_url_modified.geturl()\n",
    "            \n",
    "            product_titles.append(product_title)\n",
    "            product_urls.append(product_url)\n",
    "            \n",
    "            product_count += 1\n",
    "            \n",
    "            if popular_products_count_limit and (product_count >= popular_products_count_limit):\n",
    "                break\n",
    "                \n",
    "    return product_titles, product_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dbe061",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_titles, product_urls = get_popular_product_s_titles_and_urls(SEARCH_QUERY, TOP_N_PRODUCTS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b386b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for idx, url in enumerate(tqdm(product_urls, desc='products')):\n",
    "    # iterating over review pages\n",
    "    for i in tqdm(range(1,REVIEW_PAGES_TO_SCRAPE_FROM_PER_PRODUCT+1), desc=\"review pages\", position=0, leave=False):\n",
    "        parsed = urlparse.urlparse(url)\n",
    "        pid = parse_qs(parsed.query)['pid'][0]\n",
    "        URL = f\"{url}&page={i}\"\n",
    "        \n",
    "        r = requests.get(URL)\n",
    "        \n",
    "        # Pause the loop for 0-1 seconds to simulate natural setting not overwhelm the server with back to back requests without any pause\n",
    "        sleep(random())\n",
    "        soup = BeautifulSoup(r.content, 'html.parser') \n",
    "\n",
    "        rows = soup.find_all('div',attrs={'class':'col _2wzgFH K0kLPL'})\n",
    "\n",
    "        for row in rows:\n",
    "\n",
    "            # finding all rows within the block\n",
    "            sub_row = row.find_all('div',attrs={'class':'row'})\n",
    "\n",
    "            # extracting text\n",
    "            rating = sub_row[0].find('div').text\n",
    "            summary = sub_row[0].find('p').text\n",
    "            summary = summary.strip()\n",
    "            review = sub_row[1].find_all('div')[2].text\n",
    "            review = review.strip()\n",
    "\n",
    "            # appending to data\n",
    "            dataset.append({'product_title':product_titles[idx], 'rating': rating, 'summary': summary, 'review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63373e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc841779",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_reviews = df.shape[0]\n",
    "print(f\"Count of reviews:{count_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./flipkart_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac33334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
